{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Implicit ALS model","metadata":{}},{"cell_type":"code","source":"# Installing latest implicit library for ALS\n\n!pip install --upgrade implicit","metadata":{"execution":{"iopub.status.busy":"2022-04-22T19:55:21.077170Z","iopub.execute_input":"2022-04-22T19:55:21.077953Z","iopub.status.idle":"2022-04-22T19:55:31.127920Z","shell.execute_reply.started":"2022-04-22T19:55:21.077850Z","shell.execute_reply":"2022-04-22T19:55:31.126982Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Importing required libraries \n\nimport os\nimport pandas as pd\nimport numpy as np\nfrom scipy.sparse import coo_matrix\nimport implicit\nfrom implicit.evaluation import mean_average_precision_at_k\nimport glob\n#import reco\nfrom tqdm import tqdm\nimport datetime","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:25:28.809612Z","iopub.execute_input":"2022-04-22T20:25:28.810265Z","iopub.status.idle":"2022-04-22T20:25:28.815084Z","shell.execute_reply.started":"2022-04-22T20:25:28.810227Z","shell.execute_reply":"2022-04-22T20:25:28.814291Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Importing data\n\ntransactions = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/transactions_train.csv', dtype={'article_id': str}, parse_dates=['t_dat'])\nsample_submission = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv')\ncustomers = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/customers.csv')\narticles = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/articles.csv', dtype={'article_id': str})","metadata":{"execution":{"iopub.status.busy":"2022-04-22T19:55:31.588190Z","iopub.execute_input":"2022-04-22T19:55:31.588416Z","iopub.status.idle":"2022-04-22T19:56:48.436722Z","shell.execute_reply.started":"2022-04-22T19:55:31.588384Z","shell.execute_reply":"2022-04-22T19:56:48.435962Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Due to the large volume of data, we are only using the data after 2020-09-14\n\ntransactions = transactions[transactions['t_dat'] > '2020-09-14']\ntransactions.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-22T19:56:48.438631Z","iopub.execute_input":"2022-04-22T19:56:48.438913Z","iopub.status.idle":"2022-04-22T19:56:49.220219Z","shell.execute_reply.started":"2022-04-22T19:56:48.438878Z","shell.execute_reply":"2022-04-22T19:56:49.219416Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Assigning incremental ids to customers and articles\n\nall_customers = customers['customer_id'].unique().tolist()\nall_articles = articles['article_id'].unique().tolist()\n\ncustomer_ids = dict(list(enumerate(all_customers)))\narticle_ids = dict(list(enumerate(all_articles)))\n\ntransactions['customer_id'] = transactions['customer_id'].map({u: uidx for uidx, u in customer_ids.items()})\ntransactions['article_id'] = transactions['article_id'].map({i: iidx for iidx, i in article_ids.items()})\n\n# delete the original dataframes to save memory\ndel customers, articles","metadata":{"execution":{"iopub.status.busy":"2022-04-22T19:57:36.489226Z","iopub.execute_input":"2022-04-22T19:57:36.489490Z","iopub.status.idle":"2022-04-22T19:57:38.776340Z","shell.execute_reply.started":"2022-04-22T19:57:36.489459Z","shell.execute_reply":"2022-04-22T19:57:38.775622Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Creating coo_matrix (customer x article) and csr matrix (customer x article)\n\nrow = transactions['customer_id'].values\ncol = transactions['article_id'].values\ndata = np.ones(transactions.shape[0])\ncoo_train = coo_matrix((data, (row, col)), shape=(len(all_customers), len(all_articles)))\ncoo_train","metadata":{"execution":{"iopub.status.busy":"2022-04-22T19:57:43.275502Z","iopub.execute_input":"2022-04-22T19:57:43.276301Z","iopub.status.idle":"2022-04-22T19:57:43.287611Z","shell.execute_reply.started":"2022-04-22T19:57:43.276262Z","shell.execute_reply":"2022-04-22T19:57:43.286888Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# try fitting the model on training data for 2 interations\n\nmodel = implicit.als.AlternatingLeastSquares(factors=10, iterations=2, use_gpu=True, calculate_training_loss=True, random_state=2022)\nmodel.fit(coo_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:02:59.288025Z","iopub.execute_input":"2022-04-22T20:02:59.288296Z","iopub.status.idle":"2022-04-22T20:02:59.394629Z","shell.execute_reply.started":"2022-04-22T20:02:59.288265Z","shell.execute_reply":"2022-04-22T20:02:59.393861Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Tuning Hyperparameter factors & iterations","metadata":{}},{"cell_type":"code","source":"# Function to transform a dataframe with transactions into a COO sparse (articles x customers) matrix\ndef to_customer_article_coo(transactions):\n    row = transactions['customer_id'].values\n    col = transactions['article_id'].values\n    data = np.ones(transactions.shape[0])\n    coo = coo_matrix((data, (row, col)), shape=(len(all_customers), len(all_articles)))\n    return coo\n\n# Function to Split a dataframe into training (3 weeks) and validation data (1 week)\ndef split_data(transactions, validation_days=7):\n    validation_cut = transactions['t_dat'].max() - pd.Timedelta(validation_days)\n\n    df_train = transactions[transactions['t_dat'] < validation_cut]\n    df_val = transactions[transactions['t_dat'] >= validation_cut]\n    return df_train, df_val\n\n# Function to split data into training and validation and generate corresponding matrices\n# coo_train: training data in COO sparse format and as (customers x articles)\n# csr_train: training data in CSR sparse format and as (customers x articles)\n# csr_val:  validation data in CSR sparse format and as (customers x articles)\ndef get_val_matrices(transactions, validation_days=7):\n    df_train, df_val = split_data(transactions, validation_days=validation_days)\n    coo_train = to_customer_article_coo(df_train)\n    coo_val = to_customer_article_coo(df_val)\n\n    csr_train = coo_train.tocsr()\n    csr_val = coo_val.tocsr()\n    \n    return {'coo_train': coo_train,\n            'csr_train': csr_train,\n            'csr_val': csr_val\n          }\n\n# Train an ALS model over matrices and validate with the evaluation matrix MAP@12\n# factors: embeddings dimension\ndef validate(matrices, factors=200, iterations=20, regularization=0.01, show_progress=True):\n    coo_train, csr_train, csr_val = matrices['coo_train'], matrices['csr_train'], matrices['csr_val']\n    \n    model = implicit.als.AlternatingLeastSquares(factors=factors, \n                                                 iterations=iterations, \n                                                 regularization=regularization, \n                                                 random_state=7,\n                                                 use_gpu=True)\n    model.fit(coo_train, show_progress=show_progress)\n    \n    # The MAPK by implicit doesn't allow to calculate allowing repeated articles, which is the case.\n    # TODO: change MAP@12 to a library that allows repeated articles in prediction\n    map12 = mean_average_precision_at_k(model, csr_train, csr_val, K=12, show_progress=show_progress, num_threads=4)\n    print(f\"Factors: {factors:>3} - Iterations: {iterations:>2} - Regularization: {regularization:4.3f} ==> MAP@12: {map12:6.5f}\")\n    return map12","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:03:01.494261Z","iopub.execute_input":"2022-04-22T20:03:01.494989Z","iopub.status.idle":"2022-04-22T20:03:01.505727Z","shell.execute_reply.started":"2022-04-22T20:03:01.494955Z","shell.execute_reply":"2022-04-22T20:03:01.505044Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"matrices = get_val_matrices(transactions)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:03:03.026595Z","iopub.execute_input":"2022-04-22T20:03:03.027161Z","iopub.status.idle":"2022-04-22T20:03:03.070999Z","shell.execute_reply.started":"2022-04-22T20:03:03.027121Z","shell.execute_reply":"2022-04-22T20:03:03.070316Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# GridSearch\nbest_map12 = 0\nfor factors in [40, 50, 60, 100, 200, 500, 1000]:\n    for iterations in [3, 12, 14, 15, 20]:\n        for regularization in [0.01]:\n            map12 = validate(matrices, factors, iterations, regularization, show_progress=False)\n            if map12 > best_map12:\n                best_map12 = map12\n                best_params = {'factors': factors, 'iterations': iterations, 'regularization': regularization}\n                print(f\"Best MAP@12 found. Updating: {best_params}\")\n\n# delete the matrices to save memory\ndel matrices","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:04:25.787508Z","iopub.execute_input":"2022-04-22T20:04:25.787988Z","iopub.status.idle":"2022-04-22T20:07:02.259292Z","shell.execute_reply.started":"2022-04-22T20:04:25.787950Z","shell.execute_reply":"2022-04-22T20:07:02.258586Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# The best performing parameters are as follow\nbest_params","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:07:02.260911Z","iopub.execute_input":"2022-04-22T20:07:02.261159Z","iopub.status.idle":"2022-04-22T20:07:02.268866Z","shell.execute_reply.started":"2022-04-22T20:07:02.261126Z","shell.execute_reply":"2022-04-22T20:07:02.266264Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Train over the full dataset and generate submission csv","metadata":{}},{"cell_type":"code","source":"#Training over the full dataset\n\ncoo_train = to_customer_article_coo(transactions)\ncsr_train = coo_train.tocsr()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:07:02.270151Z","iopub.execute_input":"2022-04-22T20:07:02.270460Z","iopub.status.idle":"2022-04-22T20:07:02.296063Z","shell.execute_reply.started":"2022-04-22T20:07:02.270417Z","shell.execute_reply":"2022-04-22T20:07:02.295437Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def train(coo_train, factors=200, iterations=15, regularization=0.01, show_progress=True):\n    model = implicit.als.AlternatingLeastSquares(factors=factors, \n                                                 iterations=iterations, \n                                                 regularization=regularization, \n                                                 random_state=7,\n                                                 use_gpu=True)\n    model.fit(coo_train, show_progress=show_progress)\n    return model\n\nbest_params","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:07:02.297671Z","iopub.execute_input":"2022-04-22T20:07:02.297959Z","iopub.status.idle":"2022-04-22T20:07:02.305339Z","shell.execute_reply.started":"2022-04-22T20:07:02.297925Z","shell.execute_reply":"2022-04-22T20:07:02.304523Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model = train(coo_train, **best_params)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:07:02.306847Z","iopub.execute_input":"2022-04-22T20:07:02.307382Z","iopub.status.idle":"2022-04-22T20:07:03.751625Z","shell.execute_reply.started":"2022-04-22T20:07:02.307347Z","shell.execute_reply":"2022-04-22T20:07:03.750924Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Submission\n\n# This is a baseline prediction provided by other competitors, we will use it to fill in null entries produced by our ALS model\nheng_df = pd.read_csv('../input/heng-zhengs-time-is-our-best-friend-v2-submission/not_so_fancy_but_fast_benchmark.csv')\n\n\ndef submit(model, csr_train, custs, heng_df, submission_name=\"submission.csv\"):\n    preds = []\n    batch_size = 2000\n\n    for startidx in range(0, len(custs), batch_size):\n        \n        batch = custs[startidx : startidx + batch_size]\n        ids, scores = model.recommend(batch, csr_train[batch], N=12, filter_already_liked_items=False)\n        \n        for i, customerid in enumerate(batch):\n            customer_id = customer_ids[customerid]\n            customer_articles = ids[i]\n            articleids = [article_ids[article_id] for article_id in customer_articles]\n            preds.append((customer_id, ' '.join(articleids)))\n\n    df_preds = pd.DataFrame(preds, columns=['customer_id', 'prediction'])\n            \n    # For cold start / unseen customers we will use Heng Zheng's baseline preditions to fill in\n    df_preds = pd.merge(heng_df, df_preds, how='left', on='customer_id', suffixes=('_fill', '_als'))\n    df_preds.loc[~df_preds['prediction_als'].isnull(), 'prediction'] = df_preds['prediction_als']\n    df_preds.loc[df_preds['prediction_als'].isnull(), 'prediction'] = df_preds['prediction_fill']\n    df_preds = df_preds[['customer_id', 'prediction']]\n    df_preds.to_csv(submission_name, index=False)\n    \n    display(df_preds.head())\n    print(df_preds.shape)\n    \n    return df_preds","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:08:37.532341Z","iopub.execute_input":"2022-04-22T20:08:37.532634Z","iopub.status.idle":"2022-04-22T20:08:42.958678Z","shell.execute_reply.started":"2022-04-22T20:08:37.532589Z","shell.execute_reply":"2022-04-22T20:08:42.957932Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"transactions_customers = transactions['customer_id'].unique().tolist()\n\nlen(transactions_customers)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:08:42.960325Z","iopub.execute_input":"2022-04-22T20:08:42.960573Z","iopub.status.idle":"2022-04-22T20:08:42.976911Z","shell.execute_reply.started":"2022-04-22T20:08:42.960540Z","shell.execute_reply":"2022-04-22T20:08:42.976263Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# generate submission csv\ndf_preds = submit(model, csr_train, transactions_customers, heng_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:09:14.161105Z","iopub.execute_input":"2022-04-22T20:09:14.161370Z","iopub.status.idle":"2022-04-22T20:09:30.454007Z","shell.execute_reply.started":"2022-04-22T20:09:14.161341Z","shell.execute_reply":"2022-04-22T20:09:30.451803Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"The test score given by kaggle of our model is 0.0183 (MAP@12 score), ranked 1630 out of 2395 teams.","metadata":{}},{"cell_type":"markdown","source":"# Time Decaying Popularity","metadata":{}},{"cell_type":"markdown","source":"This is a heuristic-based model. Other competitors work show that popularity and repetition is the major trend of transactions.\nSo we decide to use the following two heuristics to guide our model:\n1. Recommend most bought items from last 4 weeks.\n1. Recommend popular items from last 2 weeks weighted down by time.","metadata":{}},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# read in the transaction data again\ntransactions = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/transactions_train.csv', dtype={'article_id': str}, parse_dates=['t_dat'])","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:26:29.891534Z","iopub.execute_input":"2022-04-22T20:26:29.892075Z","iopub.status.idle":"2022-04-22T20:27:10.462271Z","shell.execute_reply.started":"2022-04-22T20:26:29.892036Z","shell.execute_reply":"2022-04-22T20:27:10.461554Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Because of the large volume of data, we will only use the last five weeks of data. Among those five weeks, the first four weeks will be used as four training set and the last week will be our validation set","metadata":{}},{"cell_type":"code","source":"transactions[\"t_dat\"] = pd.to_datetime(transactions[\"t_dat\"])\ntrain1 = transactions.loc[(transactions[\"t_dat\"] >= datetime.datetime(2020,9,8)) & (transactions['t_dat'] < datetime.datetime(2020,9,16))]\ntrain2 = transactions.loc[(transactions[\"t_dat\"] >= datetime.datetime(2020,9,1)) & (transactions['t_dat'] < datetime.datetime(2020,9,8))]\ntrain3 = transactions.loc[(transactions[\"t_dat\"] >= datetime.datetime(2020,8,23)) & (transactions['t_dat'] < datetime.datetime(2020,9,1))]\ntrain4 = transactions.loc[(transactions[\"t_dat\"] >= datetime.datetime(2020,8,15)) & (transactions['t_dat'] < datetime.datetime(2020,8,23))]\n\nval = transactions.loc[transactions[\"t_dat\"] >= datetime.datetime(2020,9,16)]","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:28:42.925932Z","iopub.execute_input":"2022-04-22T20:28:42.926201Z","iopub.status.idle":"2022-04-22T20:28:44.587463Z","shell.execute_reply.started":"2022-04-22T20:28:42.926173Z","shell.execute_reply":"2022-04-22T20:28:44.586750Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# List of all purchases per user (has repetitions)\npositive_items_per_user1 = train1.groupby(['customer_id'])['article_id'].apply(list)\npositive_items_per_user2 = train2.groupby(['customer_id'])['article_id'].apply(list)\npositive_items_per_user3 = train3.groupby(['customer_id'])['article_id'].apply(list)\npositive_items_per_user4 = train4.groupby(['customer_id'])['article_id'].apply(list)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:29:21.136524Z","iopub.execute_input":"2022-04-22T20:29:21.137124Z","iopub.status.idle":"2022-04-22T20:29:27.946435Z","shell.execute_reply.started":"2022-04-22T20:29:21.137084Z","shell.execute_reply":"2022-04-22T20:29:27.945557Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### Time decay based popularity for items\n\nSimply speaking, items bought more recently having more weight in the popularity list. In simple words, an item A bought 5 times on the first day of the train period is inferior than an item B bought 4 times on the last day of the train period.","metadata":{}},{"cell_type":"code","source":"train = pd.concat([train1, train2], axis=0)\ntrain['pop_factor'] = train['t_dat'].apply(lambda x: 1/(datetime.datetime(2020,9,16) - x).days)\npopular_items_group = train.groupby(['article_id'])['pop_factor'].sum()\n\n_, popular_items = zip(*sorted(zip(popular_items_group, popular_items_group.keys()))[::-1])\n\ntrain['pop_factor'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:30:55.629569Z","iopub.execute_input":"2022-04-22T20:30:55.630315Z","iopub.status.idle":"2022-04-22T20:31:05.258253Z","shell.execute_reply.started":"2022-04-22T20:30:55.630275Z","shell.execute_reply":"2022-04-22T20:31:05.257518Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# The function to calculate our average precision @ K\ndef apk(actual, predicted, k=12):\n    if len(predicted)>k:\n        predicted = predicted[:k]\n\n    score = 0.0\n    num_hits = 0.0\n\n    for i,p in enumerate(predicted):\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits / (i+1.0)\n\n    if not actual:\n        return 0.0\n\n    return score / min(len(actual), k)\n\n# Develop on the previous function and calculate MAP@K\ndef mapk(actual, predicted, k=12):\n    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:32:05.360492Z","iopub.execute_input":"2022-04-22T20:32:05.360993Z","iopub.status.idle":"2022-04-22T20:32:05.368176Z","shell.execute_reply.started":"2022-04-22T20:32:05.360949Z","shell.execute_reply":"2022-04-22T20:32:05.367432Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# List of all purchases per user in validation set \npositive_items_val = val.groupby(['customer_id'])['article_id'].apply(list)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:33:10.169105Z","iopub.execute_input":"2022-04-22T20:33:10.169920Z","iopub.status.idle":"2022-04-22T20:33:11.842790Z","shell.execute_reply.started":"2022-04-22T20:33:10.169876Z","shell.execute_reply":"2022-04-22T20:33:11.842068Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# creating validation set that corresponding to the format of our test set\nval_users = positive_items_val.keys()\nval_items = []\n\nfor i,user in tqdm(enumerate(val_users)):\n    val_items.append(positive_items_val[user])\n    \nprint(\"Total users in validation:\", len(val_users))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:34:17.444302Z","iopub.execute_input":"2022-04-22T20:34:17.444829Z","iopub.status.idle":"2022-04-22T20:34:17.851478Z","shell.execute_reply.started":"2022-04-22T20:34:17.444787Z","shell.execute_reply":"2022-04-22T20:34:17.850700Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"Validate our model on the validation set with metric MAP@12","metadata":{}},{"cell_type":"code","source":"from collections import Counter\noutputs = []\ncnt = 0\n\npopular_items = list(popular_items)\n\nfor user in tqdm(val_users):\n    user_output = []\n    if user in positive_items_per_user1.keys():\n        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user1[user]).most_common()}\n        user_output += list(most_common_items_of_user.keys())[:12]\n    if user in positive_items_per_user2.keys():\n        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user2[user]).most_common()}\n        user_output += list(most_common_items_of_user.keys())[:12]\n    if user in positive_items_per_user3.keys():\n        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user3[user]).most_common()}\n        user_output += list(most_common_items_of_user.keys())[:12]\n    if user in positive_items_per_user4.keys():\n        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user4[user]).most_common()}\n        user_output += list(most_common_items_of_user.keys())[:12]\n    \n    user_output += list(popular_items[:12 - len(user_output)])\n    outputs.append(user_output)\n    \nprint(\"MAP@12 Score on Validation set:\", mapk(val_items, outputs))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:35:43.135222Z","iopub.execute_input":"2022-04-22T20:35:43.135502Z","iopub.status.idle":"2022-04-22T20:35:47.989828Z","shell.execute_reply.started":"2022-04-22T20:35:43.135471Z","shell.execute_reply":"2022-04-22T20:35:47.988987Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"## Predict on the test set and generate submission csv","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv\")\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:36:16.113492Z","iopub.execute_input":"2022-04-22T20:36:16.114157Z","iopub.status.idle":"2022-04-22T20:36:18.643243Z","shell.execute_reply.started":"2022-04-22T20:36:16.114117Z","shell.execute_reply":"2022-04-22T20:36:18.642511Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\noutputs = []\ncnt = 0\n\nfor user in tqdm(submission['customer_id']):\n    user_output = []\n    if user in positive_items_per_user1.keys():\n        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user1[user]).most_common()}\n        user_output += list(most_common_items_of_user.keys())[:12]\n    if user in positive_items_per_user2.keys():\n        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user2[user]).most_common()}\n        user_output += list(most_common_items_of_user.keys())[:12 - len(user_output)]\n    if user in positive_items_per_user3.keys():\n        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user3[user]).most_common()}\n        user_output += list(most_common_items_of_user.keys())[:12 - len(user_output)]\n    if user in positive_items_per_user4.keys():\n        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user4[user]).most_common()}\n        user_output += list(most_common_items_of_user.keys())[:12 - len(user_output)]\n    \n    user_output += list(popular_items[:12 - len(user_output)])\n    outputs.append(user_output)\n    \nstr_outputs = []\nfor output in outputs:\n    str_outputs.append(\" \".join([str(x) for x in output]))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:36:22.496942Z","iopub.execute_input":"2022-04-22T20:36:22.497199Z","iopub.status.idle":"2022-04-22T20:36:41.876592Z","shell.execute_reply.started":"2022-04-22T20:36:22.497170Z","shell.execute_reply":"2022-04-22T20:36:41.875842Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"submission['prediction'] = str_outputs\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:36:41.878228Z","iopub.execute_input":"2022-04-22T20:36:41.878485Z","iopub.status.idle":"2022-04-22T20:36:53.265357Z","shell.execute_reply.started":"2022-04-22T20:36:41.878450Z","shell.execute_reply":"2022-04-22T20:36:53.264551Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"The test score given by kaggle of our model is 0.0216 (MAP@12 score), ranked 1118 out of 2395 teams.","metadata":{}}]}