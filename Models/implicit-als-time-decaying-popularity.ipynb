{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Installing latest implicit library for ALS\n\n!pip install --upgrade implicit","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:53:32.951713Z","iopub.execute_input":"2022-04-24T02:53:32.952303Z","iopub.status.idle":"2022-04-24T02:53:40.308671Z","shell.execute_reply.started":"2022-04-24T02:53:32.952206Z","shell.execute_reply":"2022-04-24T02:53:40.307800Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Importing required libraries \n\nimport os\nimport pandas as pd\nimport numpy as np\nfrom scipy.sparse import coo_matrix\nimport implicit\nfrom implicit.evaluation import mean_average_precision_at_k\nimport glob\n#import reco\nfrom tqdm import tqdm\nimport datetime","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:53:40.310788Z","iopub.execute_input":"2022-04-24T02:53:40.311110Z","iopub.status.idle":"2022-04-24T02:53:40.448800Z","shell.execute_reply.started":"2022-04-24T02:53:40.311071Z","shell.execute_reply":"2022-04-24T02:53:40.447880Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Time Decaying Popularity","metadata":{}},{"cell_type":"markdown","source":"This is a heuristic-based model. Other competitors work show that popularity and repetition is the major trend of transactions.\nSo we decide to use the following two heuristics to guide our model:\n1. Recommend most bought items from last 4 weeks.\n1. Recommend popular items from last 2 weeks weighted down by time.This is a heuristic-based model. Other competitors work show that popularity and repetition is the major trend of transactions.","metadata":{}},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# read in the transaction data again\ndf_transactions = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/transactions_train.csv', dtype={'article_id': str}, parse_dates=['t_dat'])\ndf_transactions[\"t_dat\"] = pd.to_datetime(df_transactions[\"t_dat\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:53:40.450408Z","iopub.execute_input":"2022-04-24T02:53:40.450656Z","iopub.status.idle":"2022-04-24T02:54:22.451908Z","shell.execute_reply.started":"2022-04-24T02:53:40.450619Z","shell.execute_reply":"2022-04-24T02:54:22.451012Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Because of the large volume of data, we will only use the last five weeks of data. Among those five weeks, the first four weeks will be used as four training set and the last week will be our validation set","metadata":{}},{"cell_type":"code","source":"# function to generate four training sets each with one week of transaction data\ndef generate_train_sets(df, dates=[(9,16), (9,8), (9,1), (8,23), (8,15)]):\n    train_sets = []\n    for i in range(len(dates)-1):\n        m1, d1 = dates[i]\n        m2, d2 = dates[i+1]\n        df_train = df.loc[(df['t_dat']>= datetime.datetime(2020, m2, d2)) & (df['t_dat'] < datetime.datetime(2020, m1, d1))]\n        train_sets.append(df_train)\n    return train_sets","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:56:49.646388Z","iopub.execute_input":"2022-04-24T02:56:49.646672Z","iopub.status.idle":"2022-04-24T02:56:49.652766Z","shell.execute_reply.started":"2022-04-24T02:56:49.646642Z","shell.execute_reply":"2022-04-24T02:56:49.652011Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_sets = generate_train_sets(df_transactions)\n# use the last week of transaction data as our validation data\nval_set = df_transactions.loc[df_transactions[\"t_dat\"] >= datetime.datetime(2020,9,16)]","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:56:50.077311Z","iopub.execute_input":"2022-04-24T02:56:50.077796Z","iopub.status.idle":"2022-04-24T02:56:50.929636Z","shell.execute_reply.started":"2022-04-24T02:56:50.077762Z","shell.execute_reply":"2022-04-24T02:56:50.928877Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# function to generate X_train, y_train for each training set (each week of data)\n# X_train: each entry is a customer_id\n# y_train: each entry is a list of all purchased items per user (has repetitions)\ndef generate_purchase_lists(train_sets):\n    purchase_lists = []\n    for df_train in train_sets:\n        df_purchase = df_train.groupby(['customer_id']).agg({'article_id':lambda x:list(x)})\n        purchase_lists.append(df_purchase)\n    return purchase_lists","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:56:50.931138Z","iopub.execute_input":"2022-04-24T02:56:50.931383Z","iopub.status.idle":"2022-04-24T02:56:50.937017Z","shell.execute_reply.started":"2022-04-24T02:56:50.931349Z","shell.execute_reply":"2022-04-24T02:56:50.936063Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"purchase_lists = generate_purchase_lists(train_sets)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:56:54.675304Z","iopub.execute_input":"2022-04-24T02:56:54.676129Z","iopub.status.idle":"2022-04-24T02:56:58.303322Z","shell.execute_reply.started":"2022-04-24T02:56:54.676081Z","shell.execute_reply":"2022-04-24T02:56:58.302561Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Time decay based popularity for items\n\nSimply speaking, items bought more recently having more weight in the popularity list. In simple words, an item A bought 5 times on the first day of the train period is inferior than an item B bought 4 times on the last day of the train period.\n\n$\\text{pop_factor} = \\frac{1}{\\text{# days to 2020-9-16}}$","metadata":{}},{"cell_type":"markdown","source":"find most popular items in the last two weeks ranked by their pop_factor","metadata":{}},{"cell_type":"code","source":"# Calculate popularity factor for each row\ndf_train = pd.concat(train_sets[:2], axis=0)\ndf_train['pop_factor'] = df_train['t_dat'].apply(lambda x: 1/(datetime.datetime(2020,9,16)-x).days)\n# df_train[['t_dat', 'pop_factor']].drop_duplicates()\n\n# sort article_id by the sum of its pop_factor\npopular_items = df_train.groupby(['article_id']).agg({'pop_factor':'sum'}).reset_index().sort_values('pop_factor', ascending=False)['article_id'].to_list()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:57:12.340936Z","iopub.execute_input":"2022-04-24T02:57:12.341216Z","iopub.status.idle":"2022-04-24T02:57:21.189661Z","shell.execute_reply.started":"2022-04-24T02:57:12.341188Z","shell.execute_reply":"2022-04-24T02:57:21.188932Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# generate list of all purchases per user in validation set \ndf_purchases_val = val_set.groupby(['customer_id']).agg({'article_id':lambda x:list(x)}).reset_index()\n# generate X_val and y_val\nX_val = df_purchases_val['customer_id'].tolist()\ny_val = df_purchases_val['article_id'].tolist()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:57:21.912383Z","iopub.execute_input":"2022-04-24T02:57:21.912668Z","iopub.status.idle":"2022-04-24T02:57:22.595157Z","shell.execute_reply.started":"2022-04-24T02:57:21.912637Z","shell.execute_reply":"2022-04-24T02:57:22.594402Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# The function to calculate our average precision @ K\ndef apk(actual, predicted, k=12):\n    if len(predicted)>k:\n        predicted = predicted[:k]\n\n    score = 0.0\n    num_hits = 0.0\n\n    for i,p in enumerate(predicted):\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits / (i+1.0)\n\n    if not actual:\n        return 0.0\n\n    return score / min(len(actual), k)\n\n# Develop on the previous function and calculate MAP@K\ndef mapk(actual, predicted, k=12):\n    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:57:24.249729Z","iopub.execute_input":"2022-04-24T02:57:24.250330Z","iopub.status.idle":"2022-04-24T02:57:24.257841Z","shell.execute_reply.started":"2022-04-24T02:57:24.250287Z","shell.execute_reply":"2022-04-24T02:57:24.257128Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Validate our model on the validation set with metric MAP@12","metadata":{}},{"cell_type":"code","source":"from collections import Counter\ndef make_prediction(X):\n    predictions = []\n    for u in tqdm(X):\n        pred = []\n        for i in range(len(purchase_lists)):\n            if u in purchase_lists[i].index:\n                pred += [a_id for a_id, count in Counter(purchase_lists[i].loc[u].tolist()[0]).most_common()][:12]\n\n        pred += popular_items[:12-len(pred)]\n        predictions.append(pred)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:57:32.779157Z","iopub.execute_input":"2022-04-24T02:57:32.779448Z","iopub.status.idle":"2022-04-24T02:57:32.788462Z","shell.execute_reply.started":"2022-04-24T02:57:32.779416Z","shell.execute_reply":"2022-04-24T02:57:32.787781Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"ypred = make_prediction(X_val)\nprint(mapk(y_val, ypred))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:57:33.381424Z","iopub.execute_input":"2022-04-24T02:57:33.382013Z","iopub.status.idle":"2022-04-24T02:57:40.678567Z","shell.execute_reply.started":"2022-04-24T02:57:33.381969Z","shell.execute_reply":"2022-04-24T02:57:40.677559Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Predict on the test set and generate submission csv","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv\")\nsubmission.head()\n\n# repeat the preprocessing process\ntrain_sets = generate_train_sets(df_transactions, dates=[(9,23), (9,16), (9,8), (8,31), (8,23)])\npurchase_lists = generate_purchase_lists(train_sets)\ndf_train = pd.concat(train_sets[:2], axis=0)\ndf_train['pop_factor'] = df_train['t_dat'].apply(lambda x: 1/(datetime.datetime(2020,9,23)-x).days)\npopular_items = df_train.groupby(['article_id']).agg({'pop_factor':'sum'}).reset_index().sort_values('pop_factor', ascending=False)['article_id'].to_list()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:58:13.274700Z","iopub.execute_input":"2022-04-24T02:58:13.275110Z","iopub.status.idle":"2022-04-24T02:58:31.416398Z","shell.execute_reply.started":"2022-04-24T02:58:13.275070Z","shell.execute_reply":"2022-04-24T02:58:31.415626Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"ypred = make_prediction(submission['customer_id'].tolist())\nstr_ypred = []\nfor pred in ypred:\n    str_ypred.append(\" \".join([str(i) for i in pred]))\nsubmission['prediction'] = str_ypred\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:58:32.552919Z","iopub.execute_input":"2022-04-24T02:58:32.553339Z","iopub.status.idle":"2022-04-24T03:01:19.430077Z","shell.execute_reply.started":"2022-04-24T02:58:32.553302Z","shell.execute_reply":"2022-04-24T03:01:19.428695Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"The test score given by kaggle of our model is 0.0216 (MAP@12 score), ranked 1118 out of 2395 teams.","metadata":{}},{"cell_type":"code","source":"del df_transactions, train_sets, val_set, purchase_lists, popular_items, df_train, df_purchases_val, X_val, y_val, ypred, str_ypred","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:02:03.930591Z","iopub.execute_input":"2022-04-24T03:02:03.930864Z","iopub.status.idle":"2022-04-24T03:02:04.995352Z","shell.execute_reply.started":"2022-04-24T03:02:03.930814Z","shell.execute_reply":"2022-04-24T03:02:04.994580Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Implicit ALS model","metadata":{}},{"cell_type":"code","source":"# Importing data\n\ndf_transactions = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/transactions_train.csv', dtype={'article_id': str}, parse_dates=['t_dat'])\nsample_submission = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv')\ndf_customers = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/customers.csv')\ndf_articles = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/articles.csv', dtype={'article_id': str})","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:02:26.145992Z","iopub.execute_input":"2022-04-24T03:02:26.146280Z","iopub.status.idle":"2022-04-24T03:03:11.421665Z","shell.execute_reply.started":"2022-04-24T03:02:26.146252Z","shell.execute_reply":"2022-04-24T03:03:11.420881Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def preprocessing(df_t, df_c, df_a):\n    # Due to the large volume of data, we are only using the data after 2020-09-14\n    df_t = df_t[df_t['t_dat'] > '2020-09-14']\n    \n    # create index for customer_id and article_id and create corresponding mapping between id and index\n    customer_map = dict(list(enumerate(df_c['customer_id'].unique().tolist())))\n    customer_map_inv = {customer_id: idx for idx, customer_id in customer_map.items()}\n    article_map = dict(list(enumerate(df_a['article_id'].unique().tolist())))\n    article_map_inv = {article_id: idx for idx, article_id in article_map.items()}\n    \n    # replace customer_id and article_id with index to save memory\n    df_t['customer_id'] = df_t['customer_id'].apply(lambda x:customer_map_inv[x])\n    df_t['article_id'] = df_t['article_id'].apply(lambda x:article_map_inv[x])\n    \n    return df_t, customer_map, article_map","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:03:11.423383Z","iopub.execute_input":"2022-04-24T03:03:11.423633Z","iopub.status.idle":"2022-04-24T03:03:11.430631Z","shell.execute_reply.started":"2022-04-24T03:03:11.423599Z","shell.execute_reply":"2022-04-24T03:03:11.429658Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df_transactions, customer_map, article_map = preprocessing(df_transactions, df_customers, df_articles)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:03:11.431933Z","iopub.execute_input":"2022-04-24T03:03:11.432333Z","iopub.status.idle":"2022-04-24T03:03:13.882857Z","shell.execute_reply.started":"2022-04-24T03:03:11.432298Z","shell.execute_reply":"2022-04-24T03:03:13.881985Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"del df_customers, df_articles","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:03:13.887446Z","iopub.execute_input":"2022-04-24T03:03:13.887949Z","iopub.status.idle":"2022-04-24T03:03:13.995495Z","shell.execute_reply.started":"2022-04-24T03:03:13.887907Z","shell.execute_reply":"2022-04-24T03:03:13.994743Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# function to generate coo_matrix (customer x article) from transaction dataframe\ndef generate_coo_matrix(df_t):\n    row = df_t['customer_id'].values\n    col = df_t['article_id'].values\n    data = np.ones(df_t.shape[0])\n    return coo_matrix((data, (row, col)), shape=(len(customer_map), len(article_map)))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:04:27.887445Z","iopub.execute_input":"2022-04-24T03:04:27.887709Z","iopub.status.idle":"2022-04-24T03:04:27.893679Z","shell.execute_reply.started":"2022-04-24T03:04:27.887680Z","shell.execute_reply":"2022-04-24T03:04:27.892545Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_coo = generate_coo_matrix(df_transactions)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:04:29.495621Z","iopub.execute_input":"2022-04-24T03:04:29.495894Z","iopub.status.idle":"2022-04-24T03:04:29.504663Z","shell.execute_reply.started":"2022-04-24T03:04:29.495863Z","shell.execute_reply":"2022-04-24T03:04:29.503879Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Tuning Hyperparameter factors & iterations","metadata":{}},{"cell_type":"code","source":"# Function to Split a dataframe into training (3 weeks) and validation data (1 week)\ndef split_data(df_t, num_days_val=7):\n    threshold = df_t['t_dat'].max() - pd.Timedelta(num_days_val)\n\n    df_train = df_t[df_t['t_dat'] < threshold]\n    df_val = df_t[df_t['t_dat'] >= threshold]\n    return df_train, df_val\n\n# Function to split data into training and validation and generate corresponding matrices\n# coo_train: training data in COO sparse format and as (customers x articles)\n# csr_train: training data in CSR sparse format and as (customers x articles)\n# csr_val:  validation data in CSR sparse format and as (customers x articles)\ndef generate_val_data(df_t, num_days_val=7):\n    df_train, df_val = split_data(df_t, num_days_val)\n    coo_train = generate_coo_matrix(df_train)\n    coo_val = generate_coo_matrix(df_val)\n\n    csr_train = coo_train.tocsr()\n    csr_val = coo_val.tocsr()\n    \n    return coo_train, csr_train, csr_val\n\n# Train an ALS model over matrices and validate with the evaluation matrix MAP@12\ndef validate(data, embed_dims=200, iters=20, alpha=0.01, show_progress=True):\n    coo_train, csr_train, csr_val = data\n    \n    model = implicit.als.AlternatingLeastSquares(factors=embed_dims, \n                                                 iterations=iters, \n                                                 regularization=alpha, \n                                                 random_state=2022,\n                                                 use_gpu=True)\n    model.fit(coo_train, show_progress=show_progress)\n    \n    # The MAPK by implicit doesn't allow to calculate allowing repeated articles, which is the case.\n    score = mean_average_precision_at_k(model, csr_train, csr_val, K=12, show_progress=show_progress, num_threads=4)\n    if show_progress:\n        print(\"Embedding_dimensions: {}, Iterations: {}, Regularization: {}\".format(embed_dims, iters, alpha))\n        print(\"MAP@12: \", score)\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:04:38.216265Z","iopub.execute_input":"2022-04-24T03:04:38.216523Z","iopub.status.idle":"2022-04-24T03:04:38.229319Z","shell.execute_reply.started":"2022-04-24T03:04:38.216496Z","shell.execute_reply":"2022-04-24T03:04:38.228512Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"val_data = generate_val_data(df_transactions)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:04:40.818280Z","iopub.execute_input":"2022-04-24T03:04:40.818916Z","iopub.status.idle":"2022-04-24T03:04:40.872255Z","shell.execute_reply.started":"2022-04-24T03:04:40.818879Z","shell.execute_reply":"2022-04-24T03:04:40.871512Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"params_dict = {\n    'embed_dims': [40, 50, 60, 100, 200, 500, 1000],\n    'iters': [3, 5, 7, 9, 11],\n    'alpha': [0.1, 0.05, 0.01]\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:04:41.264460Z","iopub.execute_input":"2022-04-24T03:04:41.265000Z","iopub.status.idle":"2022-04-24T03:04:41.269642Z","shell.execute_reply.started":"2022-04-24T03:04:41.264962Z","shell.execute_reply":"2022-04-24T03:04:41.268793Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# GridSearch\ndef gridsearch(params_dict, val_data):\n    best_score = 0\n    for embed_dims in params_dict['embed_dims']:\n        for iters in params_dict['iters']:\n            for alpha in params_dict['alpha']:\n                score = validate(val_data, embed_dims, iters, alpha, show_progress=False)\n                if score > best_score:\n                    best_score = score\n                    best_params = {'factors': embed_dims, 'iterations': iters, 'regularization': alpha}\n                    print(\"Best MAP@12 found. Updating: \"+str(best_params))\n    return best_params","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:04:41.828044Z","iopub.execute_input":"2022-04-24T03:04:41.828933Z","iopub.status.idle":"2022-04-24T03:04:41.835552Z","shell.execute_reply.started":"2022-04-24T03:04:41.828898Z","shell.execute_reply":"2022-04-24T03:04:41.834708Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# The best performing parameters are as follow\nbest_params = gridsearch(params_dict, val_data)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:04:45.437375Z","iopub.execute_input":"2022-04-24T03:04:45.437852Z","iopub.status.idle":"2022-04-24T03:09:16.689907Z","shell.execute_reply.started":"2022-04-24T03:04:45.437795Z","shell.execute_reply":"2022-04-24T03:09:16.688246Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"del val_data","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:09:16.694942Z","iopub.execute_input":"2022-04-24T03:09:16.697272Z","iopub.status.idle":"2022-04-24T03:09:16.705134Z","shell.execute_reply.started":"2022-04-24T03:09:16.697207Z","shell.execute_reply":"2022-04-24T03:09:16.702249Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## Train over the full dataset and generate submission csv","metadata":{}},{"cell_type":"code","source":"# generate coo_matrix and csr_matrix using all transactions data\n\ncoo_train = generate_coo_matrix(df_transactions)\ncsr_train = coo_train.tocsr()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:09:48.269901Z","iopub.execute_input":"2022-04-24T03:09:48.270436Z","iopub.status.idle":"2022-04-24T03:09:48.297846Z","shell.execute_reply.started":"2022-04-24T03:09:48.270399Z","shell.execute_reply":"2022-04-24T03:09:48.297129Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# train model\nbest_params['random_state'] = 2022\nbest_params['use_gpu'] = True\nmodel_als = implicit.als.AlternatingLeastSquares(**best_params)\nmodel_als.fit(coo_train, show_progress=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:09:49.239414Z","iopub.execute_input":"2022-04-24T03:09:49.241527Z","iopub.status.idle":"2022-04-24T03:09:50.655986Z","shell.execute_reply.started":"2022-04-24T03:09:49.241489Z","shell.execute_reply":"2022-04-24T03:09:50.655285Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def generate_submission(model_als, csr_train, unique_customers, df_sup):\n    # make top12 recommendation on all users in training data\n    preds, _ = model_als.recommend(unique_customers, csr_train[unique_customers], N=12, filter_already_liked_items=False)\n    # map indices to the original customer id\n    customer_id = [customer_map[i] for i in unique_customers]\n    # map indices to the original article id and join the 12 ids into a single string as required by the submission format\n    prediction = []\n    for pred in preds:\n        prediction.append(\" \".join([article_map[i] for i in pred]))\n    # merge with our supplement predictions to fill in predictions for users unseen in training\n    df_pred_als = pd.DataFrame({'customer_id': customer_id, 'prediction': prediction})\n    df_final_pred = pd.merge(df_sup, df_pred_als, on='customer_id', how='left', suffixes=('_sup', '_als'))\n    final_predictions = []\n    for i in range(len(df_final_pred)):\n        if df_final_pred.iloc[i, :]['prediction_als'] is np.nan:\n            final_predictions.append(df_final_pred.iloc[i, :]['prediction_sup'])\n        else:\n            final_predictions.append(df_final_pred.iloc[i, :]['prediction_als'])\n    df_final_pred['prediction'] = final_predictions\n    df_final_pred = df_final_pred[['customer_id', 'prediction']]\n    # save to csv\n    df_final_pred.to_csv(\"submission.csv\", index=False)\n    \n    return df_final_pred","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:19:35.294482Z","iopub.execute_input":"2022-04-24T03:19:35.294742Z","iopub.status.idle":"2022-04-24T03:19:35.304748Z","shell.execute_reply.started":"2022-04-24T03:19:35.294713Z","shell.execute_reply":"2022-04-24T03:19:35.304092Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# use predictions from our Time Decaying Popularity model as our supplements\ndf_sup = submission\nunique_customers = df_transactions['customer_id'].unique().tolist()\ndf_final_pred = generate_submission(model_als, csr_train, unique_customers, df_sup)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:24:03.609146Z","iopub.execute_input":"2022-04-24T03:24:03.609411Z","iopub.status.idle":"2022-04-24T03:28:44.109169Z","shell.execute_reply.started":"2022-04-24T03:24:03.609382Z","shell.execute_reply":"2022-04-24T03:28:44.108386Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"df_final_pred.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T03:29:58.664542Z","iopub.execute_input":"2022-04-24T03:29:58.664797Z","iopub.status.idle":"2022-04-24T03:29:58.674081Z","shell.execute_reply.started":"2022-04-24T03:29:58.664768Z","shell.execute_reply":"2022-04-24T03:29:58.673152Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"The test score given by kaggle of our model is 0.0183 (MAP@12 score), ranked 1630 out of 2395 teams.","metadata":{}}]}